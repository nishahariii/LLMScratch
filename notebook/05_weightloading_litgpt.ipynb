{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1b8722d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\kgn\\\\OneDrive - PowerSchool\\\\PowerSchool\\\\Release Script\\\\Python\\\\Data Scientist\\\\LLMScratch\\\\notebook'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91e49450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\kgn\\\\OneDrive - PowerSchool\\\\PowerSchool\\\\Release Script\\\\Python\\\\Data Scientist\\\\LLMScratch'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28ae7fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "litgpt version: 0.4.3\n",
      "torch version: 2.2.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"litgpt\", \n",
    "        \"torch\",\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "828529c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "litgpt version: 0.4.3\n",
      "torch version: 2.2.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"litgpt\", \n",
    "        \"torch\",\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15736bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repo_id: list\n",
      "Please specify --repo_id <repo_id>. Available values:\n",
      "codellama/CodeLlama-13b-hf\n",
      "codellama/CodeLlama-13b-Instruct-hf\n",
      "codellama/CodeLlama-13b-Python-hf\n",
      "codellama/CodeLlama-34b-hf\n",
      "codellama/CodeLlama-34b-Instruct-hf\n",
      "codellama/CodeLlama-34b-Python-hf\n",
      "codellama/CodeLlama-70b-hf\n",
      "codellama/CodeLlama-70b-Instruct-hf\n",
      "codellama/CodeLlama-70b-Python-hf\n",
      "codellama/CodeLlama-7b-hf\n",
      "codellama/CodeLlama-7b-Instruct-hf\n",
      "codellama/CodeLlama-7b-Python-hf\n",
      "databricks/dolly-v2-12b\n",
      "databricks/dolly-v2-3b\n",
      "databricks/dolly-v2-7b\n",
      "EleutherAI/pythia-1.4b\n",
      "EleutherAI/pythia-1.4b-deduped\n",
      "EleutherAI/pythia-12b\n",
      "EleutherAI/pythia-12b-deduped\n",
      "EleutherAI/pythia-14m\n",
      "EleutherAI/pythia-160m\n",
      "EleutherAI/pythia-160m-deduped\n",
      "EleutherAI/pythia-1b\n",
      "EleutherAI/pythia-1b-deduped\n",
      "EleutherAI/pythia-2.8b\n",
      "EleutherAI/pythia-2.8b-deduped\n",
      "EleutherAI/pythia-31m\n",
      "EleutherAI/pythia-410m\n",
      "EleutherAI/pythia-410m-deduped\n",
      "EleutherAI/pythia-6.9b\n",
      "EleutherAI/pythia-6.9b-deduped\n",
      "EleutherAI/pythia-70m\n",
      "EleutherAI/pythia-70m-deduped\n",
      "garage-bAInd/Camel-Platypus2-13B\n",
      "garage-bAInd/Camel-Platypus2-70B\n",
      "garage-bAInd/Platypus-30B\n",
      "garage-bAInd/Platypus2-13B\n",
      "garage-bAInd/Platypus2-70B\n",
      "garage-bAInd/Platypus2-70B-instruct\n",
      "garage-bAInd/Platypus2-7B\n",
      "garage-bAInd/Stable-Platypus2-13B\n",
      "google/codegemma-7b-it\n",
      "google/gemma-2b\n",
      "google/gemma-2b-it\n",
      "google/gemma-7b\n",
      "google/gemma-7b-it\n",
      "h2oai/h2o-danube2-1.8b-chat\n",
      "keeeeenw/MicroLlama\n",
      "lmsys/longchat-13b-16k\n",
      "lmsys/longchat-7b-16k\n",
      "lmsys/vicuna-13b-v1.3\n",
      "lmsys/vicuna-13b-v1.5\n",
      "lmsys/vicuna-13b-v1.5-16k\n",
      "lmsys/vicuna-33b-v1.3\n",
      "lmsys/vicuna-7b-v1.3\n",
      "lmsys/vicuna-7b-v1.5\n",
      "lmsys/vicuna-7b-v1.5-16k\n",
      "meta-llama/Llama-2-13b-chat-hf\n",
      "meta-llama/Llama-2-13b-hf\n",
      "meta-llama/Llama-2-70b-chat-hf\n",
      "meta-llama/Llama-2-70b-hf\n",
      "meta-llama/Llama-2-7b-chat-hf\n",
      "meta-llama/Llama-2-7b-hf\n",
      "meta-llama/Meta-Llama-3-70B\n",
      "meta-llama/Meta-Llama-3-70B-Instruct\n",
      "meta-llama/Meta-Llama-3-8B\n",
      "meta-llama/Meta-Llama-3-8B-Instruct\n",
      "microsoft/phi-1_5\n",
      "microsoft/phi-2\n",
      "microsoft/Phi-3-mini-4k-instruct\n",
      "mistralai/Mistral-7B-Instruct-v0.1\n",
      "mistralai/Mistral-7B-Instruct-v0.2\n",
      "mistralai/Mistral-7B-Instruct-v0.3\n",
      "mistralai/Mistral-7B-v0.1\n",
      "mistralai/Mistral-7B-v0.3\n",
      "mistralai/Mixtral-8x7B-Instruct-v0.1\n",
      "mistralai/Mixtral-8x7B-v0.1\n",
      "NousResearch/Nous-Hermes-13b\n",
      "NousResearch/Nous-Hermes-llama-2-7b\n",
      "NousResearch/Nous-Hermes-Llama2-13b\n",
      "openlm-research/open_llama_13b\n",
      "openlm-research/open_llama_3b\n",
      "openlm-research/open_llama_7b\n",
      "stabilityai/FreeWilly2\n",
      "stabilityai/stable-code-3b\n",
      "stabilityai/stablecode-completion-alpha-3b\n",
      "stabilityai/stablecode-completion-alpha-3b-4k\n",
      "stabilityai/stablecode-instruct-alpha-3b\n",
      "stabilityai/stablelm-3b-4e1t\n",
      "stabilityai/stablelm-base-alpha-3b\n",
      "stabilityai/stablelm-base-alpha-7b\n",
      "stabilityai/stablelm-tuned-alpha-3b\n",
      "stabilityai/stablelm-tuned-alpha-7b\n",
      "stabilityai/stablelm-zephyr-3b\n",
      "tiiuae/falcon-180B\n",
      "tiiuae/falcon-180B-chat\n",
      "tiiuae/falcon-40b\n",
      "tiiuae/falcon-40b-instruct\n",
      "tiiuae/falcon-7b\n",
      "tiiuae/falcon-7b-instruct\n",
      "TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\n",
      "togethercomputer/LLaMA-2-7B-32K\n",
      "togethercomputer/RedPajama-INCITE-7B-Base\n",
      "togethercomputer/RedPajama-INCITE-7B-Chat\n",
      "togethercomputer/RedPajama-INCITE-7B-Instruct\n",
      "togethercomputer/RedPajama-INCITE-Base-3B-v1\n",
      "togethercomputer/RedPajama-INCITE-Base-7B-v0.1\n",
      "togethercomputer/RedPajama-INCITE-Chat-3B-v1\n",
      "togethercomputer/RedPajama-INCITE-Chat-7B-v0.1\n",
      "togethercomputer/RedPajama-INCITE-Instruct-3B-v1\n",
      "togethercomputer/RedPajama-INCITE-Instruct-7B-v0.1\n",
      "Trelis/Llama-2-7b-chat-hf-function-calling-v2\n",
      "unsloth/Mistral-7B-v0.2\n"
     ]
    }
   ],
   "source": [
    "!litgpt download list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8850754c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repo_id: microsoft/phi-2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kgn\\OneDrive - PowerSchool\\PowerSchool\\Release Script\\Python\\Data Scientist\\LLMScratch\\.llms3.10\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kgn\\OneDrive - PowerSchool\\PowerSchool\\Release Script\\Python\\Data Scientist\\LLMScratch\\.llms3.10\\lib\\site-packages\\huggingface_hub\\file_download.py:980: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
      "  warnings.warn(\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "\n",
      "Initializing  0%|          | 00:00<?, ?it/s\n",
      "Loading weights: model-00001-of-00002.bin:   0%|          | 00:00<?, ?it/s\n",
      "Loading weights: model-00001-of-00002.bin:   0%|          | 00:02<17:50, 10.73s/it\n",
      "Loading weights: model-00001-of-00002.bin:   1%|          | 00:02<03:18,  2.00s/it\n",
      "Loading weights: model-00001-of-00002.bin:   1%|▏         | 00:03<02:43,  1.66s/it\n",
      "Loading weights: model-00001-of-00002.bin:   3%|▎         | 00:03<01:19,  1.22it/s\n",
      "Loading weights: model-00001-of-00002.bin:   3%|▎         | 00:03<01:20,  1.20it/s\n",
      "Loading weights: model-00001-of-00002.bin:   4%|▍         | 00:04<00:59,  1.63it/s\n",
      "Loading weights: model-00001-of-00002.bin:   4%|▍         | 00:05<01:34,  1.02it/s\n",
      "Loading weights: model-00001-of-00002.bin:   5%|▍         | 00:05<01:29,  1.06it/s\n",
      "Loading weights: model-00001-of-00002.bin:   6%|▌         | 00:05<00:59,  1.58it/s\n",
      "Loading weights: model-00001-of-00002.bin:   7%|▋         | 00:06<00:59,  1.57it/s\n",
      "Loading weights: model-00001-of-00002.bin:   8%|▊         | 00:06<00:42,  2.15it/s\n",
      "Loading weights: model-00001-of-00002.bin:   8%|▊         | 00:07<00:54,  1.68it/s\n",
      "Loading weights: model-00001-of-00002.bin:  10%|▉         | 00:07<00:43,  2.07it/s\n",
      "Loading weights: model-00001-of-00002.bin:  10%|▉         | 00:07<00:49,  1.83it/s\n",
      "Loading weights: model-00001-of-00002.bin:  11%|█▏        | 00:08<00:40,  2.19it/s\n",
      "Loading weights: model-00001-of-00002.bin:  12%|█▏        | 00:08<00:46,  1.88it/s\n",
      "Loading weights: model-00001-of-00002.bin:  13%|█▎        | 00:10<01:15,  1.15it/s\n",
      "Loading weights: model-00001-of-00002.bin:  13%|█▎        | 00:10<01:21,  1.06it/s\n",
      "Loading weights: model-00001-of-00002.bin:  15%|█▍        | 00:11<01:05,  1.30it/s\n",
      "Loading weights: model-00001-of-00002.bin:  15%|█▌        | 00:12<01:12,  1.16it/s\n",
      "Loading weights: model-00001-of-00002.bin:  16%|█▋        | 00:12<00:56,  1.49it/s\n",
      "Loading weights: model-00001-of-00002.bin:  17%|█▋        | 00:13<01:01,  1.36it/s\n",
      "Loading weights: model-00001-of-00002.bin:  18%|█▊        | 00:13<00:49,  1.65it/s\n",
      "Loading weights: model-00001-of-00002.bin:  18%|█▊        | 00:16<01:58,  1.45s/it\n",
      "Loading weights: model-00001-of-00002.bin:  20%|█▉        | 00:17<01:33,  1.16s/it\n",
      "Loading weights: model-00001-of-00002.bin:  20%|██        | 00:17<01:35,  1.19s/it\n",
      "Loading weights: model-00001-of-00002.bin:  21%|██▏       | 00:18<01:13,  1.07it/s\n",
      "Loading weights: model-00001-of-00002.bin:  22%|██▏       | 00:18<01:21,  1.04s/it\n",
      "Loading weights: model-00001-of-00002.bin:  23%|██▎       | 00:19<01:06,  1.16it/s\n",
      "Loading weights: model-00001-of-00002.bin:  24%|██▎       | 00:20<01:10,  1.09it/s\n",
      "Loading weights: model-00001-of-00002.bin:  25%|██▍       | 00:20<00:54,  1.37it/s\n",
      "Loading weights: model-00001-of-00002.bin:  25%|██▌       | 00:21<00:59,  1.26it/s\n",
      "Loading weights: model-00001-of-00002.bin:  27%|██▋       | 00:21<00:43,  1.70it/s\n",
      "Loading weights: model-00001-of-00002.bin:  27%|██▋       | 00:22<00:53,  1.36it/s\n",
      "Loading weights: model-00001-of-00002.bin:  28%|██▊       | 00:23<00:48,  1.47it/s\n",
      "Loading weights: model-00001-of-00002.bin:  29%|██▊       | 00:23<00:59,  1.21it/s\n",
      "Loading weights: model-00001-of-00002.bin:  29%|██▉       | 00:23<00:46,  1.51it/s\n",
      "Loading weights: model-00001-of-00002.bin:  30%|██▉       | 00:24<00:56,  1.24it/s\n",
      "Loading weights: model-00001-of-00002.bin:  30%|███       | 00:25<01:02,  1.12it/s\n",
      "Loading weights: model-00001-of-00002.bin:  32%|███▏      | 00:25<00:47,  1.44it/s\n",
      "Loading weights: model-00001-of-00002.bin:  32%|███▏      | 00:26<00:51,  1.31it/s\n",
      "Loading weights: model-00001-of-00002.bin:  33%|███▎      | 00:26<00:42,  1.59it/s\n",
      "Loading weights: model-00001-of-00002.bin:  34%|███▍      | 00:27<00:50,  1.30it/s\n",
      "Loading weights: model-00001-of-00002.bin:  34%|███▍      | 00:27<00:39,  1.65it/s\n",
      "Loading weights: model-00001-of-00002.bin:  35%|███▌      | 00:28<00:46,  1.39it/s\n",
      "Loading weights: model-00001-of-00002.bin:  35%|███▌      | 00:29<01:29,  1.39s/it\n",
      "Loading weights: model-00001-of-00002.bin:  37%|███▋      | 00:30<01:01,  1.03it/s\n",
      "Loading weights: model-00001-of-00002.bin:  37%|███▋      | 00:30<01:02,  1.01it/s\n",
      "Loading weights: model-00001-of-00002.bin:  38%|███▊      | 00:31<00:42,  1.46it/s\n",
      "Loading weights: model-00001-of-00002.bin:  39%|███▉      | 00:31<00:43,  1.40it/s\n",
      "Loading weights: model-00001-of-00002.bin:  40%|████      | 00:32<00:42,  1.42it/s\n",
      "Loading weights: model-00001-of-00002.bin:  41%|████      | 00:32<00:44,  1.32it/s\n",
      "Loading weights: model-00001-of-00002.bin:  42%|████▏     | 00:33<00:42,  1.38it/s\n",
      "Loading weights: model-00001-of-00002.bin:  42%|████▏     | 00:34<00:50,  1.15it/s\n",
      "Loading weights: model-00001-of-00002.bin:  44%|████▎     | 00:35<00:37,  1.51it/s\n",
      "Loading weights: model-00001-of-00002.bin:  44%|████▍     | 00:35<00:44,  1.27it/s\n",
      "Loading weights: model-00001-of-00002.bin:  45%|████▌     | 00:36<00:35,  1.55it/s\n",
      "Loading weights: model-00001-of-00002.bin:  46%|████▌     | 00:36<00:43,  1.26it/s\n",
      "Loading weights: model-00001-of-00002.bin:  47%|████▋     | 00:37<00:33,  1.61it/s\n",
      "Loading weights: model-00001-of-00002.bin:  47%|████▋     | 00:37<00:37,  1.41it/s\n",
      "Loading weights: model-00001-of-00002.bin:  49%|████▊     | 00:38<00:27,  1.86it/s\n",
      "Loading weights: model-00001-of-00002.bin:  49%|████▉     | 00:38<00:31,  1.63it/s\n",
      "Loading weights: model-00001-of-00002.bin:  50%|█████     | 00:39<00:24,  2.00it/s\n",
      "Loading weights: model-00001-of-00002.bin:  51%|█████     | 00:39<00:37,  1.31it/s\n",
      "Loading weights: model-00001-of-00002.bin:  52%|█████▏    | 00:40<00:29,  1.66it/s\n",
      "Loading weights: model-00001-of-00002.bin:  52%|█████▏    | 00:40<00:26,  1.80it/s\n",
      "Loading weights: model-00001-of-00002.bin:  52%|█████▏    | 00:40<00:24,  1.95it/s\n",
      "Loading weights: model-00001-of-00002.bin:  53%|█████▎    | 00:40<00:22,  2.10it/s\n",
      "Loading weights: model-00001-of-00002.bin:  53%|█████▎    | 00:40<00:20,  2.27it/s\n",
      "Loading weights: model-00001-of-00002.bin:  54%|█████▎    | 00:40<00:20,  2.22it/s\n",
      "Loading weights: model-00001-of-00002.bin:  54%|█████▍    | 00:41<00:21,  2.11it/s\n",
      "Loading weights: model-00001-of-00002.bin:  55%|█████▍    | 00:41<00:19,  2.38it/s\n",
      "Loading weights: model-00001-of-00002.bin:  55%|█████▌    | 00:41<00:17,  2.60it/s\n",
      "Loading weights: model-00001-of-00002.bin:  55%|█████▌    | 00:41<00:15,  2.81it/s\n",
      "Loading weights: model-00001-of-00002.bin:  56%|█████▌    | 00:41<00:14,  3.05it/s\n",
      "Loading weights: model-00001-of-00002.bin:  56%|█████▋    | 00:41<00:13,  3.22it/s\n",
      "Loading weights: model-00001-of-00002.bin:  57%|█████▋    | 00:41<00:12,  3.38it/s\n",
      "Loading weights: model-00001-of-00002.bin:  57%|█████▋    | 00:41<00:12,  3.33it/s\n",
      "Loading weights: model-00001-of-00002.bin:  58%|█████▊    | 00:42<00:13,  3.15it/s\n",
      "Loading weights: model-00001-of-00002.bin:  58%|█████▊    | 00:42<00:16,  2.60it/s\n",
      "Loading weights: model-00001-of-00002.bin:  58%|█████▊    | 00:42<00:17,  2.41it/s\n",
      "Loading weights: model-00001-of-00002.bin:  59%|█████▉    | 00:42<00:16,  2.49it/s\n",
      "Loading weights: model-00001-of-00002.bin:  59%|█████▉    | 00:42<00:17,  2.30it/s\n",
      "Loading weights: model-00001-of-00002.bin:  60%|█████▉    | 00:43<00:17,  2.35it/s\n",
      "Loading weights: model-00001-of-00002.bin:  60%|██████    | 00:43<00:16,  2.37it/s\n",
      "Loading weights: model-00001-of-00002.bin:  61%|██████    | 00:43<00:16,  2.37it/s\n",
      "Loading weights: model-00001-of-00002.bin:  61%|██████    | 00:43<00:16,  2.43it/s\n",
      "Loading weights: model-00001-of-00002.bin:  61%|██████▏   | 00:43<00:14,  2.75it/s\n",
      "Loading weights: model-00001-of-00002.bin:  62%|██████▏   | 00:43<00:12,  2.95it/s\n",
      "Loading weights: model-00001-of-00002.bin:  62%|██████▏   | 00:44<00:12,  3.01it/s\n",
      "Loading weights: model-00001-of-00002.bin:  63%|██████▎   | 00:44<00:12,  3.03it/s\n",
      "Loading weights: model-00001-of-00002.bin:  63%|██████▎   | 00:44<00:11,  3.16it/s\n",
      "Loading weights: model-00001-of-00002.bin:  64%|██████▎   | 00:44<00:11,  3.22it/s\n",
      "Loading weights: model-00001-of-00002.bin:  64%|██████▍   | 00:44<00:11,  3.21it/s\n",
      "Loading weights: model-00002-of-00002.bin:  64%|██████▍   | 00:44<00:11,  3.21it/s\n",
      "Loading weights: model-00002-of-00002.bin:  64%|██████▍   | 00:48<01:55,  3.23s/it\n",
      "Loading weights: model-00002-of-00002.bin:  65%|██████▌   | 00:49<01:06,  1.90s/it\n",
      "Loading weights: model-00002-of-00002.bin:  66%|██████▌   | 00:49<01:02,  1.82s/it\n",
      "Loading weights: model-00002-of-00002.bin:  67%|██████▋   | 00:50<00:40,  1.22s/it\n",
      "Loading weights: model-00002-of-00002.bin:  67%|██████▋   | 00:50<00:44,  1.34s/it\n",
      "Loading weights: model-00002-of-00002.bin:  68%|██████▊   | 00:51<00:33,  1.03s/it\n",
      "Loading weights: model-00002-of-00002.bin:  68%|██████▊   | 00:51<00:29,  1.10it/s\n",
      "Loading weights: model-00002-of-00002.bin: 100%|██████████| 00:52<00:00, 14.27it/s\n",
      "Loading weights: model-00002-of-00002.bin: 100%|██████████| 00:52<00:00,  1.91it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting HF_HUB_ENABLE_HF_TRANSFER=1\n",
      "Converting .safetensor files to PyTorch binaries (.bin)\n",
      "checkpoints\\microsoft\\phi-2\\model-00001-of-00002.safetensors --> checkpoints\\microsoft\\phi-2\\model-00001-of-00002.bin\n",
      "checkpoints\\microsoft\\phi-2\\model-00002-of-00002.safetensors --> checkpoints\\microsoft\\phi-2\\model-00002-of-00002.bin\n",
      "Converting checkpoint files to LitGPT format.\n",
      "{'checkpoint_dir': WindowsPath('checkpoints/microsoft/phi-2'),\n",
      " 'debug_mode': False,\n",
      " 'dtype': None,\n",
      " 'model_name': None}\n",
      "Saving converted checkpoint to checkpoints\\microsoft\\phi-2\n"
     ]
    }
   ],
   "source": [
    "# !litgpt download microsoft/phi-2\n",
    "!litgpt download microsoft/phi-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1486279a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kgn\\OneDrive - PowerSchool\\PowerSchool\\Release Script\\Python\\Data Scientist\\LLMScratch\\.llms3.10\\lib\\site-packages\\litgpt\\utils.py:559: UserWarning: The file size of checkpoints\\microsoft\\phi-2\\lit_model.pth is over 4.2 GB. Using a model with more than 1B parameters on a CPU can be slow, it is recommended to switch to a GPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Llamas are herbivores and mainly eat grass, shrubs, and leaves. They can survive in high altitude and harsh environments.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from litgpt import LLM\n",
    "# List available attributes and classes in litgpt to find the correct usage\n",
    "# print(dir(litgpt))\n",
    "\n",
    "llm = LLM.load(\"microsoft/phi-2\")\n",
    "\n",
    "llm.generate(\"What do Llamas eat?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llms3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
